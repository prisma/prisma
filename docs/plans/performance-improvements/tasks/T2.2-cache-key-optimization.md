# T2.2: Optimize Cache Key Generation

**Priority**: P1  
**Track**: 2 (Query Plan Caching)  
**Effort**: Medium (2-3 days)  
**Impact**: Medium (reduces cache lookup overhead from ~5-10μs to <1μs)  
**Dependencies**: T1.1 (Strawman Query Plan Cache)

## Objective

Replace `JSON.stringify` with a faster cache key generation mechanism using structural hashing, reducing the overhead of cache lookups for repeated queries.

## Background

After implementing T1.1, the cache lookup flow is:

```typescript
// Current implementation
const cacheKey = JSON.stringify({
  modelName: query.modelName,
  action: query.action,
  query: parameterizedQuery,
})
const cached = cache.get(cacheKey)
```

`JSON.stringify` has several performance costs:

1. Full object traversal
2. String allocation proportional to query size
3. String comparison for cache lookup (O(n) where n = string length)

For complex queries (e.g., blog post page), the parameterized query can be 2KB+ of JSON, making stringify/comparison expensive.

## Proposed Solution

### Approach: Incremental Structural Hashing

Compute a hash during parameterization traversal, avoiding a second pass:

```typescript
export interface ParameterizeResult {
  parameterizedQuery: unknown
  placeholderValues: Record<string, unknown>
  placeholderPaths: string[]
  queryHash: number // NEW: Pre-computed hash
}

export function parameterizeQuery(query: unknown): ParameterizeResult {
  let hash = 0
  const placeholderValues: Record<string, unknown> = {}
  const placeholderPaths: string[] = []

  const parameterized = parameterize(query, 'default', '', {
    values: placeholderValues,
    paths: placeholderPaths,
    hash: { value: hash }, // Pass by reference for mutation
  })

  return {
    parameterizedQuery: parameterized,
    placeholderValues,
    placeholderPaths,
    queryHash: hash,
  }
}
```

### Hash Function Requirements

The hash function should:

1. Be fast (minimal per-value overhead)
2. Have good distribution (minimize collisions)
3. Support incremental updates (compute during traversal)
4. Handle all JSON value types

**Recommended**: FNV-1a (32-bit)

- Simple implementation (~10 lines)
- Fast for small inputs
- Good distribution
- Used by many hash tables

```typescript
function fnv1aHash(str: string, hash = 2166136261): number {
  for (let i = 0; i < str.length; i++) {
    hash ^= str.charCodeAt(i)
    hash = Math.imul(hash, 16777619)
  }
  return hash >>> 0
}

function hashValue(value: unknown, hash: number): number {
  switch (typeof value) {
    case 'string':
      return fnv1aHash(value, hash)
    case 'number':
      return fnv1aHash(String(value), hash)
    case 'boolean':
      return fnv1aHash(value ? 'T' : 'F', hash)
    case 'object':
      if (value === null) return fnv1aHash('null', hash)
      if (Array.isArray(value)) {
        hash = fnv1aHash('[', hash)
        for (const item of value) {
          hash = hashValue(item, hash)
        }
        return fnv1aHash(']', hash)
      }
      hash = fnv1aHash('{', hash)
      for (const [key, val] of Object.entries(value)) {
        hash = fnv1aHash(key, hash)
        hash = hashValue(val, hash)
      }
      return fnv1aHash('}', hash)
    default:
      return hash
  }
}
```

### Cache Structure with Hash

Modify `QueryPlanCache` to use hash as primary key with collision handling:

```typescript
interface CacheEntry {
  plan: QueryPlanNode
  placeholderPaths: string[]
  fullKey?: string // Stored lazily on collision
}

export class QueryPlanCache {
  readonly #cache: Map<number, CacheEntry | CacheEntry[]>

  get(hash: number, fullKeyFn: () => string): CacheEntry | undefined {
    const entry = this.#cache.get(hash)
    if (!entry) return undefined

    // Single entry (common case, no collision)
    if (!Array.isArray(entry)) {
      return entry
    }

    // Collision: need full key comparison
    const fullKey = fullKeyFn()
    return entry.find((e) => e.fullKey === fullKey)
  }

  set(hash: number, entry: CacheEntry, fullKeyFn: () => string): void {
    const existing = this.#cache.get(hash)

    if (!existing) {
      this.#cache.set(hash, entry)
      return
    }

    // Handle collision
    entry.fullKey = fullKeyFn()
    if (Array.isArray(existing)) {
      existing.push(entry)
    } else {
      existing.fullKey = fullKeyFn()
      this.#cache.set(hash, [existing, entry])
    }
  }
}
```

## Implementation Steps

### Step 1: Implement Hash Function (0.5 day)

Create `packages/client/src/runtime/core/engines/client/hash.ts`:

- FNV-1a implementation
- `hashValue()` for JSON-like values
- Unit tests for distribution and correctness

### Step 2: Integrate Hash into Parameterization (0.5 day)

Modify parameterization to compute hash during traversal:

- Add hash accumulator to context
- Hash keys and structural tokens during traversal
- Return hash with parameterized result

### Step 3: Update Cache Implementation (1 day)

Modify `QueryPlanCache`:

- Change key from string to number
- Add collision handling
- Lazy full-key generation for collision resolution
- Maintain LRU behavior

### Step 4: Benchmark and Tune (0.5 day)

- Compare performance: JSON.stringify vs hash-based
- Measure collision rate on realistic workloads
- Tune hash function if needed

## Testing Requirements

### Unit Tests

1. **Hash function tests**
   - Empty values
   - All scalar types
   - Nested objects and arrays
   - Known collision cases
   - Hash stability (same input = same output)

2. **Cache tests**
   - Hash-based lookup
   - Collision handling
   - LRU eviction with hash keys

### Integration Tests

1. **Correctness**
   - All existing client tests pass
   - Cache returns correct plan for same-shape queries
   - Different shapes produce different hashes (no false hits)

2. **Performance**
   - Measure cache lookup time: target <1μs
   - Measure hash computation time: target <5μs for complex queries

## Success Criteria

- [ ] Cache lookup overhead reduced from ~5-10μs to <1μs
- [ ] Hash collision rate <0.1% on typical workloads
- [ ] No correctness regressions (all tests pass)
- [ ] Memory usage similar or better than string-key approach

## Alternatives Considered

### Alternative 1: Symbol-based Keys

Use `Symbol.for(stringKey)` for faster equality comparison:

- **Pro**: Constant-time comparison after initial intern
- **Con**: Still requires stringify for initial intern, memory overhead

### Alternative 2: WeakMap with Query Object

Use the query object itself as key via WeakMap:

- **Pro**: No hashing needed
- **Con**: Queries are rarely identical objects; would need canonicalization

### Alternative 3: Pre-computed Keys at Generation Time

Generate unique query shape IDs during client generation:

- **Pro**: Zero runtime overhead for key generation
- **Con**: Only works for known query shapes; requires T3.2

## Files to Modify

| File                                                                | Changes                  |
| ------------------------------------------------------------------- | ------------------------ |
| New: `packages/client/src/runtime/core/engines/client/hash.ts`      | Hash implementation      |
| `packages/client/src/runtime/core/engines/client/parameterize.ts`   | Add hash computation     |
| `packages/client/src/runtime/core/engines/client/QueryPlanCache.ts` | Hash-based keys          |
| `packages/client/src/runtime/core/engines/client/ClientEngine.ts`   | Use hash in cache lookup |

## Related Tasks

- **T1.1**: Strawman Query Plan Cache (prerequisite)
- **T2.1**: Proper Parameterization (can share hash computation)
- **T3.2**: Generate Parameterization at Build Time (future optimization)
