# T1.1: Implement Strawman Query Plan Cache

**Priority**: P0 (Critical)  
**Track**: 2 - Query Plan Caching  
**Effort**: Medium (3-5 days)  
**Impact**: High (estimated 10-30x improvement for repeated queries)

## Objective

Implement a basic query plan cache using the existing `sqlcommenter-query-insights` parameterizer to validate the hypothesis that caching compiled query plans significantly improves performance.

## Background

Currently, every query execution triggers a full query compilation through the Wasm query compiler:

```typescript
// ClientEngine.request() - packages/client/src/runtime/core/engines/client/ClientEngine.ts:455-465
let queryPlan: QueryPlanNode
try {
  queryPlan = this.#withLocalPanicHandler(() =>
    this.#withCompileSpan({
      queries: [query],
      execute: () => queryCompiler.compile(queryStr) as QueryPlanNode,
    }),
  )
} catch (error) {
  throw this.#transformCompileError(error)
}

// TODO: ORM-508 - Implement query plan caching by replacing all scalar values in the query with params automatically.
const placeholderValues = {}
```

Query compilation takes ~90μs for a simple findUnique, while interpreter execution takes only ~3μs. For repeated queries with the same shape, we can cache the compiled plan and skip recompilation.

## Technical Approach

### 1. Create QueryPlanCache Class

Create `packages/client/src/runtime/core/engines/client/QueryPlanCache.ts`:

```typescript
import type { QueryPlanNode } from '@prisma/client-engine-runtime'

interface CacheEntry {
  plan: QueryPlanNode
  placeholderPaths: string[] // Ordered list of placeholder paths
}

export class QueryPlanCache {
  readonly #cache: Map<string, CacheEntry>
  readonly #maxSize: number

  constructor(maxSize = 1000) {
    this.#cache = new Map()
    this.#maxSize = maxSize
  }

  get(key: string): CacheEntry | undefined {
    const entry = this.#cache.get(key)
    if (entry) {
      // Move to end for LRU behavior
      this.#cache.delete(key)
      this.#cache.set(key, entry)
    }
    return entry
  }

  set(key: string, entry: CacheEntry): void {
    if (this.#cache.size >= this.#maxSize) {
      // Evict oldest (first) entry
      const firstKey = this.#cache.keys().next().value
      if (firstKey !== undefined) {
        this.#cache.delete(firstKey)
      }
    }
    this.#cache.set(key, entry)
  }

  clear(): void {
    this.#cache.clear()
  }

  get size(): number {
    return this.#cache.size
  }
}
```

### 2. Implement Parameterization with Value Extraction

Create `packages/client/src/runtime/core/engines/client/parameterize.ts`:

Adapt the logic from `packages/sqlcommenter-query-insights/src/parameterize/parameterize.ts` to:

1. Replace scalar values with `{ $type: "Param", name: "path.to.value" }`
2. Extract the original values into a map keyed by path
3. Return both the parameterized query (for cache key) and the values map

```typescript
export interface ParameterizeResult {
  parameterizedQuery: unknown
  placeholderValues: Record<string, unknown>
  placeholderPaths: string[] // Ordered for consistent binding
}

export function parameterizeQuery(query: unknown): ParameterizeResult {
  const placeholderValues: Record<string, unknown> = {}
  const placeholderPaths: string[] = []

  const parameterized = parameterize(query, 'default', '', placeholderValues, placeholderPaths)

  return {
    parameterizedQuery: parameterized,
    placeholderValues,
    placeholderPaths,
  }
}
```

### 3. Integrate Cache into ClientEngine

Modify `packages/client/src/runtime/core/engines/client/ClientEngine.ts`:

```typescript
class ClientEngine {
  #queryPlanCache: QueryPlanCache

  constructor(...) {
    // ...
    this.#queryPlanCache = new QueryPlanCache()
  }

  async request<T>(query: JsonQuery, options): Promise<{ data: T }> {
    const { executor, queryCompiler } = await this.#ensureStarted()

    // Step 1: Parameterize the query
    const { parameterizedQuery, placeholderValues, placeholderPaths } = parameterizeQuery(query.query)

    // Step 2: Generate cache key
    const cacheKey = JSON.stringify({
      modelName: query.modelName,
      action: query.action,
      query: parameterizedQuery,
    })

    // Step 3: Check cache
    let queryPlan: QueryPlanNode
    const cached = this.#queryPlanCache.get(cacheKey)

    if (cached) {
      queryPlan = cached.plan
    } else {
      // Step 4: Compile with parameterized query
      const queryStr = JSON.stringify({
        modelName: query.modelName,
        action: query.action,
        query: parameterizedQuery,
      })

      queryPlan = this.#withLocalPanicHandler(() =>
        this.#withCompileSpan({
          queries: [query],
          execute: () => queryCompiler.compile(queryStr) as QueryPlanNode,
        }),
      )

      this.#queryPlanCache.set(cacheKey, { plan: queryPlan, placeholderPaths })
    }

    // Step 5: Execute with placeholder values
    const result = await executor.execute({
      plan: queryPlan,
      placeholderValues,
      // ... other params
    })

    return { data: { [query.action]: result } as T }
  }
}
```

## Implementation Steps

1. **Create QueryPlanCache class** (~0.5 day)
   - Implement basic LRU cache with configurable size
   - Add unit tests for cache behavior

2. **Implement parameterization logic** (~1.5 days)
   - Adapt sqlcommenter-query-insights parameterizer
   - Add path tracking for placeholder values
   - Generate placeholder names compatible with query compiler
   - Add comprehensive unit tests

3. **Integrate into ClientEngine** (~1 day)
   - Modify `request()` method
   - Modify `requestBatch()` method
   - Handle edge cases (transactions, raw queries)

4. **Add feature flag** (~0.5 day)
   - Add `__internal.queryPlanCache` option to disable caching
   - Default to enabled

5. **Benchmarking and validation** (~1 day)
   - Add cached query benchmarks
   - Verify correctness with functional tests
   - Measure actual performance improvement

## Testing Strategy

### Unit Tests

1. **QueryPlanCache tests**
   - Cache hit/miss behavior
   - LRU eviction
   - Size limits

2. **Parameterization tests**
   - All value types (strings, numbers, booleans, dates, etc.)
   - Nested objects and arrays
   - Filter operators (equals, in, contains, etc.)
   - Order by and pagination
   - Relation queries

### Integration Tests

1. **Functional correctness**
   - Run existing client functional tests with caching enabled
   - Verify identical results with/without cache

2. **Cache invalidation scenarios**
   - Schema changes (should not affect runtime cache)
   - Different query shapes produce different cache keys

### Benchmark Tests

Add to `query-performance.bench.ts`:

```typescript
suite.add('findUnique (first call, uncached)', ...)
suite.add('findUnique (repeated, cached)', ...)
suite.add('findUnique (different IDs, cached shape)', ...)
```

## Success Criteria

- [ ] Simple findUnique performance improves from ~6k to ~50k+ ops/sec for cache hits
- [ ] Cache overhead for misses is <5% of total compilation time
- [ ] All existing tests pass with caching enabled
- [ ] No memory leaks (cache has bounded size)

## Risks and Mitigations

| Risk                                                  | Mitigation                                                         |
| ----------------------------------------------------- | ------------------------------------------------------------------ |
| Parameterization incorrectly modifies query semantics | Comprehensive unit tests; fallback to uncached for complex queries |
| Cache key generation is too slow                      | Profile and optimize; consider hash-based keys later               |
| Memory usage from cached plans is too high            | Configurable cache size; measure plan sizes in benchmarks          |
| Some queries can't be parameterized                   | Graceful fallback to uncached compilation                          |

## Dependencies

- `@prisma/sqlcommenter-query-insights` (for reference, may inline logic)
- `@prisma/client-engine-runtime` (QueryPlanNode type)

## Follow-up Tasks

After this task, we should:

- T2.1: Implement proper parameterization with named placeholders
- T2.2: Optimize cache key generation (structural hashing)
- T3.1: Add parameterization metadata to DMMF
